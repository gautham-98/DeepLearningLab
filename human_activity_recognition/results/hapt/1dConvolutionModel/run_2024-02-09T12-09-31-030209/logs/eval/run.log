Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[448   0   0   0   0   0   0   0   0   0   0   0]
 [  0 410   0   0   0   0   0   0   0   0   0   0]
 [ 17   0 363   0   0   0   0   0   0   0   0   0]
 [  0   0   0 528   0   0   1   0   0   2   0   0]
 [  4   0   0  61 492   0   4   1   0   1   0   0]
 [  0   0   0   0   0 563   0   0   2   0   0   0]
 [  2   0   0   0   0   0  15   0   0   0   0   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  23   0   3   0]
 [  0   0   0   0   0   0   0   0   0  17   0   5]
 [  0   0   0   1   0   0   2   0  11   0  16   0]
 [  0   0   0   0   0   0   2   0   0   3   0  20]]
Accuracy(balanced): 89.11
Accuracy(Unbalanced): 95.96
Accuracy(Sparse Categorical) 95.96
recall: ['100.00%', '100.00%', '95.53%', '99.44%', '87.39%', '99.65%', '88.24%', '100.00%', '88.46%', '77.27%', '53.33%', '80.00%']
precision: ['95.12%', '100.00%', '100.00%', '89.49%', '100.00%', '100.00%', '62.50%', '85.71%', '63.89%', '73.91%', '84.21%', '80.00%']
macro_f1_score: 87.65
----Evaluation completed----
