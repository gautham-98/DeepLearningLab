Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[448   0   0   0   0   0   0   0   0   0   0   0]
 [  0 410   0   0   0   0   0   0   0   0   0   0]
 [  1   0 374   0   0   0   0   0   0   0   0   5]
 [  0   0   0 496  31   0   2   0   0   2   0   0]
 [  0   0   0  22 532   0   3   3   0   1   2   0]
 [  0   0   0   0   0 548   0   0  14   0   0   3]
 [  0   0   0   0   0   0  15   0   0   1   1   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  18   0   8   0]
 [  0   0   0   0   0   0   0   0   0  22   0   0]
 [  0   0   0   0   1   0   2   0   6   0  21   0]
 [  0   0   0   0   0   0   2   0   0   9   1  13]]
Accuracy(balanced): 88.57
Accuracy(Unbalanced): 96.03
Accuracy(Sparse Categorical) 96.03
recall: ['100.00%', '100.00%', '98.42%', '93.41%', '94.49%', '96.99%', '88.24%', '100.00%', '69.23%', '100.00%', '70.00%', '52.00%']
precision: ['99.78%', '100.00%', '100.00%', '95.75%', '94.33%', '100.00%', '62.50%', '66.67%', '47.37%', '62.86%', '63.64%', '61.90%']
macro_f1_score: 83.82
----Evaluation completed----
