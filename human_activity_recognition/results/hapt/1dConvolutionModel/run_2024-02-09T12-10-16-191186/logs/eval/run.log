Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[447   0   0   0   0   0   0   0   0   0   0   1]
 [  2 408   0   0   0   0   0   0   0   0   0   0]
 [  3   2 375   0   0   0   0   0   0   0   0   0]
 [  0   0   0 498  30   0   3   0   0   0   0   0]
 [  2   0   0  13 544   0   0   1   0   0   0   3]
 [  0   0   0   0   0 550   0   0   6   0   4   5]
 [  0   0   0   0   0   0  14   0   0   0   3   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  13   0  13   0]
 [  0   0   0   0   0   0   0   0   0  14   0   8]
 [  0   1   0   0   1   0   0   1   5   0  22   0]
 [  0   0   0   0   0   0   1   0   0   2   1  21]]
Accuracy(balanced): 86.59
Accuracy(Unbalanced): 96.33
Accuracy(Sparse Categorical) 96.33
recall: ['99.78%', '99.51%', '98.68%', '93.79%', '96.63%', '97.35%', '82.35%', '100.00%', '50.00%', '63.64%', '73.33%', '84.00%']
precision: ['98.46%', '99.27%', '100.00%', '97.46%', '94.61%', '100.00%', '77.78%', '75.00%', '54.17%', '87.50%', '51.16%', '55.26%']
macro_f1_score: 84.52
----Evaluation completed----
