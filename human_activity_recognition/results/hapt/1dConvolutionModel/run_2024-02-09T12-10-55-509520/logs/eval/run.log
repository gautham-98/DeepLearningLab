Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[448   0   0   0   0   0   0   0   0   0   0   0]
 [  0 410   0   0   0   0   0   0   0   0   0   0]
 [  8   1 370   0   0   0   0   0   0   0   1   0]
 [  0   0   0 498  31   0   2   0   0   0   0   0]
 [  2   1   0  18 538   0   1   1   1   0   1   0]
 [  0   0   0   0   0 555   0   0   5   2   1   2]
 [  0   0   0   0   0   0  16   0   0   0   1   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  21   0   5   0]
 [  0   0   0   0   0   0   0   0   0  17   0   5]
 [  0   0   0   0   1   0   1   1  10   0  17   0]
 [  0   0   0   0   0   0   2   0   0   5   0  18]]
Accuracy(balanced): 88.81
Accuracy(Unbalanced): 96.39
Accuracy(Sparse Categorical) 96.39
recall: ['100.00%', '100.00%', '97.37%', '93.79%', '95.56%', '98.23%', '94.12%', '100.00%', '80.77%', '77.27%', '56.67%', '72.00%']
precision: ['97.82%', '99.51%', '100.00%', '96.51%', '94.39%', '100.00%', '72.73%', '75.00%', '56.76%', '70.83%', '65.38%', '72.00%']
macro_f1_score: 86.03
----Evaluation completed----
