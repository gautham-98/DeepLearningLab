Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[448   0   0   0   0   0   0   0   0   0   0   0]
 [  0 410   0   0   0   0   0   0   0   0   0   0]
 [  0   0 380   0   0   0   0   0   0   0   0   0]
 [  0   0   0 501  29   0   1   0   0   0   0   0]
 [  0   0   0  17 539   0   2   4   0   0   1   0]
 [  0   0   0   0   0 548   0   0   9   0   2   6]
 [  0   0   0   0   0   0  14   1   0   1   1   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  17   0   9   0]
 [  0   0   0   0   0   0   0   0   0  22   0   0]
 [  0   0   0   1   0   0   2   0   6   0  21   0]
 [  0   0   0   0   0   0   1   0   1   8   1  14]]
Accuracy(balanced): 88.40
Accuracy(Unbalanced): 96.59
Accuracy(Sparse Categorical) 96.59
recall: ['100.00%', '100.00%', '100.00%', '94.35%', '95.74%', '96.99%', '82.35%', '100.00%', '65.38%', '100.00%', '70.00%', '56.00%']
precision: ['100.00%', '100.00%', '100.00%', '96.53%', '94.89%', '100.00%', '70.00%', '54.55%', '51.52%', '70.97%', '60.00%', '70.00%']
macro_f1_score: 84.38
----Evaluation completed----
