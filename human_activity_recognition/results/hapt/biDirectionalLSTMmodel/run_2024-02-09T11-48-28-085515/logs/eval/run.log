Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[447   1   0   0   0   0   0   0   0   0   0   0]
 [  0 410   0   0   0   0   0   0   0   0   0   0]
 [  5   0 369   0   0   0   0   0   2   1   2   1]
 [  0   0   0 408 122   0   0   0   0   0   1   0]
 [  1   0   0   0 561   0   1   0   0   0   0   0]
 [  0   0   0   0   0 545   0   0   8   0   9   3]
 [  0   1   0   0   1   0  13   0   0   0   2   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  20   0   6   0]
 [  0   0   0   0   0   0   0   0   0  17   0   5]
 [  0   0   0   0   1   0   0   0   7   1  21   0]
 [  0   0   0   0   0   0   1   0   0   7   1  16]]
Accuracy(balanced): 86.21
Accuracy(Unbalanced): 93.71
Accuracy(Sparse Categorical) 93.71
recall: ['99.78%', '100.00%', '97.11%', '76.84%', '99.64%', '96.46%', '76.47%', '100.00%', '76.92%', '77.27%', '70.00%', '64.00%']
precision: ['98.68%', '99.51%', '100.00%', '100.00%', '81.90%', '100.00%', '86.67%', '100.00%', '54.05%', '65.38%', '50.00%', '64.00%']
macro_f1_score: 84.75
----Evaluation completed----
