Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[446   2   0   0   0   0   0   0   0   0   0   0]
 [  1 406   0   0   0   0   2   0   0   0   1   0]
 [  4   1 373   0   0   0   0   0   0   0   1   1]
 [  0   0   0 456  74   0   0   0   0   0   1   0]
 [  0   0   0   2 561   0   0   0   0   0   0   0]
 [  0   0   0   0   0 538   0   0  14   1   5   7]
 [  0   0   0   0   1   0  15   0   0   0   1   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  20   0   6   0]
 [  0   0   0   0   0   0   0   0   0  21   0   1]
 [  0   0   0   2   1   0   1   0   9   0  17   0]
 [  0   1   0   0   0   0   2   0   0   5   1  16]]
Accuracy(balanced): 88.23
Accuracy(Unbalanced): 95.10
Accuracy(Sparse Categorical) 95.10
recall: ['99.55%', '99.02%', '98.16%', '85.88%', '99.64%', '95.22%', '88.24%', '100.00%', '76.92%', '95.45%', '56.67%', '64.00%']
precision: ['98.89%', '99.02%', '100.00%', '99.13%', '88.07%', '100.00%', '75.00%', '100.00%', '46.51%', '77.78%', '51.52%', '64.00%']
macro_f1_score: 85.71
----Evaluation completed----
