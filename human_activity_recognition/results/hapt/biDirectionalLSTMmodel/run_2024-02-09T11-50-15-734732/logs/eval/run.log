Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[447   1   0   0   0   0   0   0   0   0   0   0]
 [  0 410   0   0   0   0   0   0   0   0   0   0]
 [  5   0 371   0   0   0   1   0   0   1   1   1]
 [  0   0   0 432  97   0   0   0   2   0   0   0]
 [  0   0   0   2 560   0   0   0   0   0   1   0]
 [  0   0   0   0   0 547   0   0   6   1   5   6]
 [  0   1   0   0   0   0  13   0   0   0   3   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  16   0  10   0]
 [  0   0   0   0   0   0   0   0   0  19   0   3]
 [  0   0   0   2   1   0   2   0   5   0  20   0]
 [  0   0   0   0   0   0   0   1   0   6   0  18]]
Accuracy(balanced): 86.51
Accuracy(Unbalanced): 94.57
Accuracy(Sparse Categorical) 94.57
recall: ['99.78%', '100.00%', '97.63%', '81.36%', '99.47%', '96.81%', '76.47%', '100.00%', '61.54%', '86.36%', '66.67%', '72.00%']
precision: ['98.89%', '99.51%', '100.00%', '99.08%', '85.11%', '100.00%', '81.25%', '85.71%', '55.17%', '70.37%', '50.00%', '64.29%']
macro_f1_score: 84.43
----Evaluation completed----
