Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[445   2   0   0   0   0   0   0   0   0   0   1]
 [  0 410   0   0   0   0   0   0   0   0   0   0]
 [  1   0 372   0   0   0   5   0   0   1   0   1]
 [  0   0   0 417 110   0   3   0   0   1   0   0]
 [  0   0   0  24 537   0   1   0   0   1   0   0]
 [  0   0   0   0   0 536   0   0   9   2   8  10]
 [  0   0   1   0   0   0  14   0   0   0   2   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   1   0  18   0   7   0]
 [  0   0   0   0   0   0   0   0   0  19   0   3]
 [  0   0   0   2   1   0   1   0   6   0  20   0]
 [  0   0   0   0   0   0   2   2   0   6   0  15]]
Accuracy(balanced): 85.88
Accuracy(Unbalanced): 92.92
Accuracy(Sparse Categorical) 92.92
recall: ['99.33%', '100.00%', '97.89%', '78.53%', '95.38%', '94.87%', '82.35%', '100.00%', '69.23%', '86.36%', '66.67%', '60.00%']
precision: ['99.78%', '99.51%', '99.73%', '94.13%', '82.87%', '100.00%', '51.85%', '75.00%', '54.55%', '63.33%', '54.05%', '50.00%']
macro_f1_score: 81.24
----Evaluation completed----
