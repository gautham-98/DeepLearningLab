Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[448   0   0   0   0   0   0   0   0   0   0   0]
 [  7 401   0   0   0   0   0   0   0   0   2   0]
 [ 15   2 360   0   1   0   0   0   0   0   0   2]
 [  0   0   0 443  63  21   2   0   1   1   0   0]
 [  0   0   0   0 562   0   1   0   0   0   0   0]
 [  0   0   0   0   0 532   0   0  14   0   9  10]
 [  0   0   0   0   1   0  14   0   0   0   2   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  19   0   7   0]
 [  0   0   0   0   0   0   0   0   0  18   0   4]
 [  0   0   0   1   0   0   1   0   7   1  20   0]
 [  0   1   0   0   0   0   0   0   0   2   0  22]]
Accuracy(balanced): 88.49
Accuracy(Unbalanced): 94.11
Accuracy(Sparse Categorical) 94.11
recall: ['100.00%', '97.80%', '94.74%', '83.43%', '99.82%', '94.16%', '82.35%', '100.00%', '73.08%', '81.82%', '66.67%', '88.00%']
precision: ['95.32%', '99.26%', '100.00%', '99.77%', '89.63%', '96.20%', '77.78%', '100.00%', '46.34%', '81.82%', '50.00%', '57.89%']
macro_f1_score: 85.57
----Evaluation completed----
