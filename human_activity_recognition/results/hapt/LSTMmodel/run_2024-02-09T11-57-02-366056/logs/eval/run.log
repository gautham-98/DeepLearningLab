Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[448   0   0   0   0   0   0   0   0   0   0   0]
 [  0 410   0   0   0   0   0   0   0   0   0   0]
 [ 16   0 362   0   0   0   0   0   0   0   0   2]
 [  0   0   0 394 133   0   3   0   0   1   0   0]
 [  0   0   0   1 561   0   1   0   0   0   0   0]
 [  0   0   0   0   0 540   0   0   7   1   7  10]
 [  0   0   0   0   1   0  14   1   0   0   1   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  20   0   6   0]
 [  0   0   0   0   0   0   0   0   0  16   0   6]
 [  0   0   0   0   1   0   1   0   9   1  18   0]
 [  0   3   0   0   0   0   1   0   0   0   0  21]]
Accuracy(balanced): 86.72
Accuracy(Unbalanced): 92.95
Accuracy(Sparse Categorical) 92.95
recall: ['100.00%', '100.00%', '95.26%', '74.20%', '99.64%', '95.58%', '82.35%', '100.00%', '76.92%', '72.73%', '60.00%', '84.00%']
precision: ['96.55%', '99.27%', '100.00%', '99.75%', '80.60%', '100.00%', '70.00%', '85.71%', '55.56%', '84.21%', '56.25%', '53.85%']
macro_f1_score: 84.20
----Evaluation completed----
