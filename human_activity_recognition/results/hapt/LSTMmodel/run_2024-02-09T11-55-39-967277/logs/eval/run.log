Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[448   0   0   0   0   0   0   0   0   0   0   0]
 [  1 409   0   0   0   0   0   0   0   0   0   0]
 [ 13   0 366   0   0   0   0   0   0   0   1   0]
 [  0   0   0 434  95   0   2   0   0   0   0   0]
 [  0   0   0   5 557   0   0   0   0   0   1   0]
 [  0   0   0   0   0 549   0   0   2   1   9   4]
 [  0   0   0   0   1   0  14   0   0   0   2   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  22   0   4   0]
 [  0   0   0   0   0   0   0   0   0  17   0   5]
 [  0   0   0   1   0   0   1   0   9   1  18   0]
 [  0   3   0   0   0   0   0   2   0   3   0  17]]
Accuracy(balanced): 87.18
Accuracy(Unbalanced): 94.51
Accuracy(Sparse Categorical) 94.51
recall: ['100.00%', '99.76%', '96.32%', '81.73%', '98.93%', '97.17%', '82.35%', '100.00%', '84.62%', '77.27%', '60.00%', '68.00%']
precision: ['96.97%', '99.27%', '100.00%', '98.64%', '85.30%', '100.00%', '82.35%', '75.00%', '66.67%', '77.27%', '51.43%', '65.38%']
macro_f1_score: 85.14
----Evaluation completed----
