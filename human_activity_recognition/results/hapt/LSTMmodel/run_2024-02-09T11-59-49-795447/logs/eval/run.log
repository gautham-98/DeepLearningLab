Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[448   0   0   0   0   0   0   0   0   0   0   0]
 [  1 409   0   0   0   0   0   0   0   0   0   0]
 [  0   0 373   0   0   0   0   0   2   1   2   2]
 [  0   0   0 450  78   0   0   0   2   1   0   0]
 [  0   0   0  24 537   0   1   1   0   0   0   0]
 [  0   0   0   0   0 541   0   0   9   0  14   1]
 [  0   0   0   0   1   0  13   0   0   0   3   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  17   0   9   0]
 [  0   0   0   0   0   0   0   0   0  19   0   3]
 [  0   0   0   0   1   0   1   0   4   1  23   0]
 [  0   0   0   0   0   0   0   0   0   4   1  20]]
Accuracy(balanced): 88.22
Accuracy(Unbalanced): 94.48
Accuracy(Sparse Categorical) 94.48
recall: ['100.00%', '99.76%', '98.16%', '84.75%', '95.38%', '95.75%', '76.47%', '100.00%', '65.38%', '86.36%', '76.67%', '80.00%']
precision: ['99.78%', '100.00%', '100.00%', '94.94%', '87.03%', '100.00%', '86.67%', '85.71%', '50.00%', '73.08%', '44.23%', '76.92%']
macro_f1_score: 85.64
----Evaluation completed----
