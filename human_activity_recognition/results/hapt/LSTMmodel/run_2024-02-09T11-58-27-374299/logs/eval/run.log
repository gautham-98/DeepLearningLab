Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[444   0   0   0   4   0   0   0   0   0   0   0]
 [  0 410   0   0   0   0   0   0   0   0   0   0]
 [  6   0 366   1   0   0   1   0   3   0   3   0]
 [  0   0   0 417 111   0   2   0   0   1   0   0]
 [  0   0   0   1 561   0   0   0   0   0   1   0]
 [  0   0   0   0   0 542   0   0   8   0  10   5]
 [  0   0   0   0   1   0  14   0   0   0   2   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  22   0   4   0]
 [  0   0   0   0   0   0   0   0   0  19   0   3]
 [  0   0   0   0   1   0   1   0  10   1  17   0]
 [  1   0   0   1   0   0   1   0   0   2   0  20]]
Accuracy(balanced): 88.29
Accuracy(Unbalanced): 93.88
Accuracy(Sparse Categorical) 93.88
recall: ['99.11%', '100.00%', '96.32%', '78.53%', '99.64%', '95.93%', '82.35%', '100.00%', '84.62%', '86.36%', '56.67%', '80.00%']
precision: ['98.45%', '100.00%', '100.00%', '99.29%', '82.74%', '100.00%', '73.68%', '100.00%', '51.16%', '82.61%', '45.95%', '71.43%']
macro_f1_score: 85.98
----Evaluation completed----
