Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[427  19   0   0   0   0   1   1   0   0   0   0]
 [  0 393   0   0   5   0  11   1   0   0   0   0]
 [ 46   5 321   0   0   0   0   3   1   0   0   4]
 [  0   0   0 397 131   0   2   1   0   0   0   0]
 [  0   0   0   0 561   0   2   0   0   0   0   0]
 [  0   0   0   0   0 527   0   0  16   0  16   6]
 [  0   0   0   0   0   0  15   1   0   0   1   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   1   0  15   0  10   0]
 [  0   0   0   0   0   0   0   0   0  22   0   0]
 [  0   0   0   2   1   0   2   0   4   1  20   0]
 [  0   1   0   0   0   0   0   4   1   4   0  15]]
Accuracy(balanced): 84.66
Accuracy(Unbalanced): 89.94
Accuracy(Sparse Categorical) 89.94
recall: ['95.31%', '95.85%', '84.47%', '74.76%', '99.64%', '93.27%', '88.24%', '100.00%', '57.69%', '100.00%', '66.67%', '60.00%']
precision: ['90.27%', '94.02%', '100.00%', '99.50%', '80.37%', '100.00%', '44.12%', '35.29%', '40.54%', '81.48%', '42.55%', '60.00%']
macro_f1_score: 78.02
----Evaluation completed----
