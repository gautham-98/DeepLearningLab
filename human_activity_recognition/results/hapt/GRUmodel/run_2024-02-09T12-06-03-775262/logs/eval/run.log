Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[445   1   0   0   0   0   0   2   0   0   0   0]
 [  1 406   0   0   0   0   0   3   0   0   0   0]
 [ 22   2 339   1   0   0   0   0   1   1   3  11]
 [  0   0   0 497  33   0   1   0   0   0   0   0]
 [  0   0   0  24 537   0   2   0   0   0   0   0]
 [  0   0   0   0   0 555   0   0   8   0   0   2]
 [  0   1   0   0   1   0  13   0   0   1   1   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  18   0   8   0]
 [  0   0   0   0   0   0   0   0   0  19   0   3]
 [  0   0   0   1   1   0   3   0   8   1  16   0]
 [  0   0   0   0   0   1   2   2   0   7   0  13]]
Accuracy(balanced): 84.35
Accuracy(Unbalanced): 94.74
Accuracy(Sparse Categorical) 94.74
recall: ['99.33%', '99.02%', '89.21%', '93.60%', '95.38%', '98.23%', '76.47%', '100.00%', '69.23%', '86.36%', '53.33%', '52.00%']
precision: ['95.09%', '99.02%', '100.00%', '95.03%', '93.88%', '99.82%', '61.90%', '46.15%', '51.43%', '65.52%', '57.14%', '44.83%']
macro_f1_score: 79.86
----Evaluation completed----
