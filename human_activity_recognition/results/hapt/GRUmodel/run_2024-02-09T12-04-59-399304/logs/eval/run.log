Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[447   0   0   0   1   0   0   0   0   0   0   0]
 [  7 403   0   0   0   0   0   0   0   0   0   0]
 [ 37   0 332   0   0   0   0   0   0   0   0  11]
 [  0   0   0 394 134   0   2   0   0   1   0   0]
 [  0   0   0   0 562   0   1   0   0   0   0   0]
 [  0   0   0   0   0 536   0   0   1   7  19   2]
 [  0   0   0   0   1   0  13   1   0   0   2   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   0   0  10   0  16   0]
 [  0   0   0   0   0   0   0   0   0  21   0   1]
 [  0   0   0   0   1   0   3   0   6   1  19   0]
 [  1   0   0   0   0   0   0   2   0   8   0  14]]
Accuracy(balanced): 82.00
Accuracy(Unbalanced): 91.20
Accuracy(Sparse Categorical) 91.20
recall: ['99.78%', '98.29%', '87.37%', '74.20%', '99.82%', '94.87%', '76.47%', '100.00%', '38.46%', '95.45%', '63.33%', '56.00%']
precision: ['90.85%', '100.00%', '100.00%', '100.00%', '80.40%', '100.00%', '68.42%', '66.67%', '58.82%', '55.26%', '33.93%', '50.00%']
macro_f1_score: 78.54
----Evaluation completed----
