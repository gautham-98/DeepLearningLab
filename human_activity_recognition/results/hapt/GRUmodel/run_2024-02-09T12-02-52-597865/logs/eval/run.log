Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[445   0   0   0   1   0   0   2   0   0   0   0]
 [ 22 375   1   0   9   0   2   1   0   0   0   0]
 [ 48   0 317   0   0   0   0   2   1   0   2  10]
 [  0   0   0 461  69   0   0   0   0   1   0   0]
 [  0   0   0  13 548   0   2   0   0   0   0   0]
 [  0   0   0   0   0 554   0   0   2   0   4   5]
 [  0   0   0   0   1   0  15   1   0   0   0   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   1   0  16   0   9   0]
 [  0   0   0   0   0   0   0   0   0  17   0   5]
 [  0   0   0   2   1   0   1   1   6   0  19   0]
 [  0   1   0   0   0   0   0   2   1   7   0  14]]
Accuracy(balanced): 83.57
Accuracy(Unbalanced): 92.19
Accuracy(Sparse Categorical) 92.19
recall: ['99.33%', '91.46%', '83.42%', '86.82%', '97.34%', '98.05%', '88.24%', '100.00%', '61.54%', '77.27%', '63.33%', '56.00%']
precision: ['86.41%', '99.73%', '99.69%', '96.85%', '87.12%', '100.00%', '71.43%', '40.00%', '61.54%', '68.00%', '55.88%', '41.18%']
macro_f1_score: 79.41
----Evaluation completed----
