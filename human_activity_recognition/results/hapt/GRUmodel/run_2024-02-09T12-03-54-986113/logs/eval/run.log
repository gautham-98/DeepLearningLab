Starting model evaluation...

====Results of Test set evaluation on sequential ====
Confusion Matrix:
[[445   2   0   0   1   0   0   0   0   0   0   0]
 [  0 393   0   0   4   0  11   2   0   0   0   0]
 [ 24   4 346   0   0   0   1   2   0   0   3   0]
 [  0   0   0 475  54   0   1   1   0   0   0   0]
 [  0   0   0   0 562   0   1   0   0   0   0   0]
 [  0   0   0   0   0 552   0   0   4   0   7   2]
 [  0   2   0   0   1   0  13   0   0   0   1   0]
 [  0   0   0   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   1   0   9   0  16   0]
 [  0   0   0   0   0   0   0   0   0  21   0   1]
 [  0   0   0   1   1   0   5   0   1   1  21   0]
 [  0   2   0   0   1   1   0   8   0   8   0   5]]
Accuracy(balanced): 80.81
Accuracy(Unbalanced): 94.21
Accuracy(Sparse Categorical) 94.21
recall: ['99.33%', '95.85%', '91.05%', '89.45%', '99.82%', '97.70%', '76.47%', '100.00%', '34.62%', '95.45%', '70.00%', '20.00%']
precision: ['94.88%', '97.52%', '100.00%', '99.79%', '90.06%', '99.82%', '39.39%', '31.58%', '64.29%', '70.00%', '43.75%', '62.50%']
macro_f1_score: 77.51
----Evaluation completed----
